{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "5c165dca-8c41-4c82-985e-1ac572f80569",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6777192",
    "execution_start": 1649992275326,
    "execution_millis": 34162,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1352.796875
   },
   "source": "%load_ext autoreload\n%autoreload 2\n\nimport wikipedia # used for search of terms, provides: DisambiguationError\n\nimport wikipediaapi # used because can get categorymembers in a given category\nwiki_wiki = wikipediaapi.Wikipedia('en')\n# Might be able to use pywikibot for everything, or at least more\n# https://stackoverflow.com/questions/71023854/how-to-find-subcategories-and-subpages-on-wikipedia-using-pywikibot\nimport pywikibot as pw # used to get AND filter hidden categories for an article\n\nimport graphviz\n\nimport stanza\nstanza.download('en') # download English model\n\n!jupyter nbextension install --py widgetsnbextension\n!jupyter nbextension enable --py widgetsnbextension\n\nnlp = stanza.Pipeline(lang='en', processors='tokenize,lemma,pos,depparse')\n\n# https://www.sbert.net/docs/pretrained_models.html\nfrom sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\n\nimport numpy as np\nimport pickle\n\nimport datetime as dt\n\nimport re\nimport requests\nimport time\nfrom collections import Counter\nfrom os.path import exists as file_exists\n ",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73b22f87cc7e4bdd9eca2ddfb2d7a4c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": "2022-04-15 03:11:19 INFO: Downloading default packages for language: en (English)...\n2022-04-15 03:11:21 INFO: File exists: /root/stanza_resources/en/default.zip.\n2022-04-15 03:11:31 INFO: Finished downloading models and saved to /root/stanza_resources.\nInstalling /root/venv/lib/python3.7/site-packages/widgetsnbextension/static -> jupyter-js-widgets\nUp to date: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js\nUp to date: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.map\n- Validating: \u001b[32mOK\u001b[0m\n\n    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n    \n          jupyter nbextension enable widgetsnbextension --py\n    \nEnabling notebook extension jupyter-js-widgets/extension...\nPaths used for configuration of notebook: \n    \t/deepnote-config/jupyter/nbconfig/notebook.json\nPaths used for configuration of notebook: \n    \t\n      - Validating: \u001b[32mOK\u001b[0m\nPaths used for configuration of notebook: \n    \t/deepnote-config/jupyter/nbconfig/notebook.json\n2022-04-15 03:11:33 INFO: Loading these models for language: en (English):\n========================\n| Processor | Package  |\n------------------------\n| tokenize  | combined |\n| pos       | combined |\n| lemma     | combined |\n| depparse  | combined |\n========================\n\n2022-04-15 03:11:33 INFO: Use device: cpu\n2022-04-15 03:11:33 INFO: Loading: tokenize\n2022-04-15 03:11:33 INFO: Loading: pos\n2022-04-15 03:11:33 INFO: Loading: lemma\n2022-04-15 03:11:33 INFO: Loading: depparse\n2022-04-15 03:11:34 INFO: Done loading processors!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "95217fc6-a700-4ed4-87b9-e97f1026db9e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d66942a1",
    "execution_start": 1649992309488,
    "execution_millis": 71,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "# # https://pypi.org/project/Wikipedia-API/\n# def print_categorymembers(categorymembers, level=0, max_level=1):\n#         for c in categorymembers.values():\n#             print(\"%s: %s (ns: %d)\" % (\"*\" * (level + 1), c.title, c.ns))\n#             if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\n#                 print_categorymembers(c.categorymembers, level=level + 1, max_level=max_level)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8b0d34e6-532b-4744-9d6e-44fde774afd8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6297f86",
    "execution_start": 1649992309565,
    "execution_millis": 97,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "\n# search_term = \"Elon Musk\"\n\n# search_results = wikipedia.search(search_term)\n# print(search_results[:10])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3d7cf02f-cbde-406b-b7c1-5559a8bb33e6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e5dbf8",
    "execution_start": 1649992309669,
    "execution_millis": 93,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "# print(search_results)\n# #https://github.com/goldsmith/Wikipedia/issues/295\n\n# first_search_term = search_results[0]\n\n# #https://github.com/goldsmith/Wikipedia/issues/295\n# try:\n#     page = wikipedia.page(first_search_term, auto_suggest=False)    \n# except wikipedia.DisambiguationError:\n#     print(\"Oops! DisambiguationError, trying next result\")\n#     first_search_term = search_results[1]\n#     page = wikipedia.page(first_search_term, auto_suggest=False)\n\n# # add gui for manual disambiguation\n# print(page.summary)\n# #print(page.categories)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "aa29c97d-251c-43e1-b517-43d3fdd5db2f",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e0a9f4cd",
    "execution_start": 1649992309771,
    "execution_millis": 110,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "\n# # Using stanza instead of nltk to save memory\n# doc = nlp(page.summary)\n# first_sentence = doc.sentences[0]\n# first_sentence.text",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "467d5151-97bf-40c9-8a80-8572e67e8f80",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7a25e8ba",
    "execution_start": 1649992309887,
    "execution_millis": 108,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 297
   },
   "source": "# print (\"{:<15} | {:<10} | {:<15} \".format('Token', 'Relation', 'Head'))\n# print (\"-\" * 50)\n  \n# # Convert sentence object to dictionary  \n# #sent_dict = doc.sentences[0].to_dict()\n# sent_dict = first_sentence.to_dict()\n\n# # iterate to print the token, relation and head\n# for word in sent_dict:\n#   print (\"{:<15} | {:<10} | {:<15} \"\n#          .format(str(word['text']),str(word['deprel']),\\\n#           str(sent_dict[word['head']-1]['text'] \\\n#           if word['head'] > 0 else 'ROOT')))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "cfa66664c707410ba0b34f5913b4767e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4c620edb",
    "execution_start": 1649992310008,
    "execution_millis": 101,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "# mvp_flag",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "db68176a-7c78-47a5-b4e8-ee382b2ba040",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5fc6046",
    "execution_start": 1649992310116,
    "execution_millis": 107,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1143
   },
   "source": "# # Look for the ROOT word of the dependency tree\n# # hopefully not the first wrod\n# root_id = 0\n# root_word = ''\n# for word in sent_dict:\n#     if word['head'] == 0:\n#         root_id = word['id']\n#         root_word = word['text']\n#         break    \n\n# print(\"first root id:\", root_id)\n# print(\"first root word:\", root_word)\n\n# # Lost TV series for some reason has ROOT as first word, so use what it's connected to as ROOT instead\n# if root_id in [1]:\n#     for word in sent_dict:\n#         if (word['head'] == 1) & (word['deprel'] in ['nsubj:pass', 'parataxis']):\n#             root_id = word['id']\n#             root_word = word['text']\n#             break\n\n# print(\"new root id:\", root_id)\n# print(\"new root word:\", root_word)\n \n\n# # Get all modifiers of ROOT word, loop up to 3 times to get enough words\n# all_dep_ids = []\n\n# for i in range(3): # at most 3 loops\n#     cur_dep_ids = []\n#     for word in sent_dict:\n#         if ((word['head'] in all_dep_ids + [root_id]) & (word['deprel'] in ['obl', 'compound','amod','nmod','conj','appos'])):\n#             cur_dep_ids.append(word['id'])\n\n#     all_dep_ids.extend(cur_dep_ids)\n#     print(i, all_dep_ids)\n#     if len(all_dep_ids) > 3: # bring back at least 3 words, if we have more, then they're too far away\n#         break\n# print(all_dep_ids)\n# all_dep_ids.append(root_id)\n\n# category_phrase_dict = dict()\n# for word in sent_dict:\n#     if (word['id'] in all_dep_ids):\n#         category_phrase_dict[word['id']] = (word['text'], word['deprel'])\n\n# print(category_phrase_dict)\n\n# category_phrase = []\n# for k,v in category_phrase_dict.items():\n#     category_phrase.append(v[0])\n\n# print('category_phrase:', category_phrase)\n# index_root_word = category_phrase.index(root_word)\n# category_phrase = category_phrase[:index_root_word+1]\n\n# category_phrase\n\n# # lop off everything after the root word - didn't work well, pros and cons\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c5510fec-e739-4988-bd2d-9a657a850dbe",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "92df5486",
    "execution_start": 1649992310231,
    "execution_millis": 134,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "# sent_dict",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b4512ea6-42e0-4115-ba46-2db8488bcb92",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ee489451",
    "execution_start": 1649992310376,
    "execution_millis": 149,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 567
   },
   "source": "# id_word = {}\n# root_id = 0\n# for word in sent_dict:\n#     if word['upos'] != 'PUNCT':\n#         if word['head'] == 0:\n#             root_id = str(word['id']) \n#         id_word[str(word['id'])] = str(word['id']) + ':' + word['text'] + ':' + word['upos'] + ':' + word['xpos']\n\n# # Create Digraph object\n# sent_tree = graphviz.Digraph()\n\n# # Add just the nodes from first traversal of dict\n# for k, v in id_word.items(): \n#     # Add nodes\n#     # https://graphviz.org/doc/info/shapes.html\n#     if k == root_id:\n#         sent_tree.node(k, v, shape='star')    \n#     else:\n#         sent_tree.node(k, v, shape='egg')\n\n\n# # Traverse dict again to add all the relationships\n# for word in sent_dict:\n#     if (word['upos'] != 'PUNCT') & (str(word['head']) != '0'):        \n#         sent_tree.edge(str(word['id']), str(word['head']), label=word['deprel'])\n\n# # Visualize the graph\n# sent_tree.unflatten(stagger=2)  ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0e9e10a5-7014-4c4e-8c8b-a2f962588f24",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f726caa0",
    "execution_start": 1649992310535,
    "execution_millis": 1325,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 410.9375,
    "deepnote_output_heights": [
     97.9375
    ]
   },
   "source": "def get_categories_from_wiki_article(article):\n    # use pywikibot because it can filter hidden 'meta' categories that aren't needed\n    # https://stackoverflow.com/questions/54526821/how-to-identify-wikipedia-categories-in-python\n    site = pw.Site(\"en\", \"wikipedia\")\n    non_hidden = [\n        cat.title()[:]\n        for cat in pw.Page(site, article).categories()\n        if 'hidden' not in cat.categoryinfo\n    ]\n    \n    return(non_hidden)\n\nget_categories_from_wiki_article('Cryptocurrency')",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "['Category:Applications of cryptography',\n 'Category:Cryptocurrencies',\n 'Category:Decentralization',\n 'Category:Financial technology',\n 'Category:Uberisation']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0345c1b6-4d3a-496a-888f-7d7868396dfe",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "52164554",
    "execution_start": 1649992311870,
    "execution_millis": 151,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 981
   },
   "source": "def get_best_categories_for_term(wiki_term, wiki_cats, nlp_cat_phrase):\n    # remove parens and anyting inside them\n    wiki_term = re.sub(r'\\([^)]*\\)', '', wiki_term)\n    print('wiki_cats:', wiki_cats)\n    print('')\n\n    # https://stackoverflow.com/questions/65199011/is-there-a-way-to-check-similarity-between-two-full-sentences-in-python\n    rem_term_cats = [' '.join([wiki_term])] + wiki_cats\n    rem_first = model.encode(rem_term_cats)\n\n    print(\"Remove wiki-cats too close to actual term(first term)\")\n    print(rem_term_cats)\n    cos_remove = util.pytorch_cos_sim(rem_first, rem_first)[0].numpy()\n    print(cos_remove)\n    rem_idx = np.where(cos_remove > .7)[0]\n    #because first item is our search term here, but we need to remove items from wiki_cats, so subtract 1\n    rem_idx_from_wiki_cats = rem_idx[1:]-1\n    print(rem_idx_from_wiki_cats)\n    wiki_cats = [j for i, j in enumerate(wiki_cats) if i not in rem_idx_from_wiki_cats]\n    print('after rem:', wiki_cats)\n\n\n    keep_cat_cats = [' '.join(nlp_cat_phrase)] + wiki_cats\n    keep_first = model.encode(keep_cat_cats)\n\n    print(\"Keep wiki-cats not too far to found category(first term)\")\n    print(keep_cat_cats)\n    keep_cos = util.pytorch_cos_sim(keep_first, keep_first)[0].numpy()\n    print(keep_cos)\n    keep_idx = np.where(keep_cos > .7)[0]\n\n    keep_idx_from_wiki_cats = keep_idx[1:]-1\n\n    print('keep idx:', keep_idx_from_wiki_cats)\n    print('pre-last-filt:', wiki_cats)\n\n    # if we got anything with a decent score, keep those, otherwise everything\n    \n    if len(keep_idx_from_wiki_cats) >= 2:\n        wiki_cats = [j for i, j in enumerate(wiki_cats) if i in keep_idx_from_wiki_cats]\n    else:\n        # keep Top 5 categories iof filtering doesn't return much\n        cats_cos = list(zip(keep_cat_cats, keep_cos))\n        top_cats_cos = sorted(cats_cos, key=lambda x: x[1], reverse=True)[1:6]\n        wiki_cats = [i[0] for i in top_cats_cos]\n\n\n\n    print('post-last-filt:', wiki_cats)\n\n    return wiki_cats",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "506c43c6944a4e21aca5fd8fed4dbffb",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a880090d",
    "execution_start": 1649992312038,
    "execution_millis": 126,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 315
   },
   "source": "def get_first_unambiguous_wiki_term_and_page(search_term):\n    search_results = wikipedia.search(search_term)\n\n    first_wiki_term = search_results[0]    \n    #https://github.com/goldsmith/Wikipedia/issues/295\n    try:\n        page = wikipedia.page(first_wiki_term, auto_suggest=False)    \n    except wikipedia.DisambiguationError:\n        print(\"Oops! DisambiguationError, trying next result\")\n        first_wiki_term = search_results[1]\n        page = wikipedia.page(first_wiki_term, auto_suggest=False)\n\n    print('first_wiki_term:', first_wiki_term)\n    return first_wiki_term, page",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "79157f5e58544eccb0e3beffdf0c921b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b5e4c19b",
    "execution_start": 1649992312174,
    "execution_millis": 175,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "def get_stanza_dict_of_first_sentence(wiki_summary_text):\n    # Using stanza instead of nltk to save memory\n    doc = nlp(wiki_summary_text)\n    return doc.sentences[0].to_dict()\n    #first_sentence.text",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a95664ab78ad42149f1a97d86eaad459",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b199f49e",
    "execution_start": 1649992312365,
    "execution_millis": 691,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 130.1875
   },
   "source": "first_wiki_term, wiki_page = get_first_unambiguous_wiki_term_and_page('Gamestop short squeeze')\n#graph_sent(get_stanza_dict_of_first_sentence(wiki_page.summary))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "first_wiki_term: GameStop short squeeze\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "ca7f6bde2617453a883dfdf42d3bfe6c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f33b6a45",
    "execution_start": 1649992313069,
    "execution_millis": 201,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1341
   },
   "source": "def get_nlp_category_phrase(wiki_page):\n    \n    wiki_page_text = wiki_page.summary\n    # # Using stanza instead of nltk to save memory\n    # doc = nlp(wiki_page_text)\n    # first_sentence = doc.sentences[0]\n    # #first_sentence.text\n    sent_dict = get_stanza_dict_of_first_sentence(wiki_page_text)\n\n    # Look for the ROOT word of the dependency tree\n    # hopefully not the first word\n    root_id = 0\n    root_word = ''\n    for word in sent_dict:\n        if word['head'] == 0:\n            root_id = word['id']\n            root_word = word['text']\n            break    \n\n    # print(\"first root id:\", root_id)\n    # print(\"first root word:\", root_word)            \n\n    # Lost TV series for some reason has ROOT as first word\n    if root_id in [1]:\n        for word in sent_dict:\n            if (word['head'] == 1) & (word['deprel'] in ['nsubj:pass', 'parataxis']):\n                root_id = word['id']                \n                root_word = word['text']\n                break\n\n    # print(\"new root id:\", root_id)\n    # print(\"new root word:\", root_word)\n\n    # Get all modifiers of ROOT word, loop up to 3 times to get enough words\n    all_dep_ids = []\n\n    for i in range(3):  # at most 3 loops\n        cur_dep_ids = []\n        for word in sent_dict:\n            if ((word['head'] in all_dep_ids + [root_id]) & (word['deprel'] in ['obl', 'compound','amod','nmod','conj','appos'])):\n                cur_dep_ids.append(word['id'])\n\n        all_dep_ids.extend(cur_dep_ids)\n        #print(i, all_dep_ids)\n        if len(all_dep_ids) > 2:    # bring back at least 4 words, if we have more, then they're too far away\n            break\n    #print(all_dep_ids)\n    all_dep_ids.append(root_id)\n\n    category_phrase_dict = dict()\n    for word in sent_dict:\n        if (word['id'] in all_dep_ids):\n            category_phrase_dict[word['id']] = word['text']\n\n    #print(category_phrase_dict)\n\n    nlp_category_phrase = []\n    for k,v in category_phrase_dict.items():\n        nlp_category_phrase.append(v)\n    #print('**', search_term, '**', first_wiki_term, '**', nlp_category_phrase)\n    #print(wiki_page.categories)\n\n    # print(nlp_category_phrase)\n    index_root_word = nlp_category_phrase.index(root_word)\n    \n    # this was an attempt to cut off the phrases at the root word, but some continue past it, iPhone for example\n    #nlp_category_phrase = nlp_category_phrase[:index_root_word+1]\n\n    print('nlp phrase:', nlp_category_phrase)\n    return nlp_category_phrase\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "f8d4a36d-74c3-4c6a-b98a-4fc5f90944dc",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f6ff4a33",
    "execution_start": 1649992313295,
    "execution_millis": 92,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 297
   },
   "source": "def get_category_from_search_term(search_term):   \n    \n    first_wiki_term, wiki_page = get_first_unambiguous_wiki_term_and_page(search_term)\n\n    nlp_category_phrase = get_nlp_category_phrase(wiki_page)\n\n    raw_wiki_cats = get_categories_from_wiki_article(first_wiki_term)\n\n    best_wiki_cats = get_best_categories_for_term(first_wiki_term, raw_wiki_cats, nlp_category_phrase)\n\n    expanded_year_wiki_cats = get_all_combined_wiki_cats(best_wiki_cats)\n\n    return nlp_category_phrase, expanded_year_wiki_cats, best_wiki_cats, first_wiki_term",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0556ab71-2a7f-4b7e-a29c-9f0025b162b5",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1649992313432,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3e50ee7188af4e538211787b2021583e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1649992313433,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e9e03895-64b9-4cbe-8a35-933cbb247596",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1649992313434,
    "execution_millis": 295888123,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "970109d2-d932-4b3d-a78b-0617a6f8722d",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f49348e0",
    "execution_start": 1649992313476,
    "execution_millis": 92,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 225
   },
   "source": "def get_wiki_wiki_pages_for_cat_members(category):\n    wiki_cat = ''\n    try:\n        wiki_cat = wiki_wiki.page(category)        \n    except requests.exceptions.SSLError:\n        print(\"SSLError exception caught!!!!!!!!!!!!!!!\")\n        time.sleep(5)\n        wiki_cat = wiki_wiki.page(category)\n    return wiki_cat",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "183082e5-f014-423e-9e88-aae9818bbbb8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3b6a7705",
    "execution_start": 1649992313609,
    "execution_millis": 615,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1048.25,
    "deepnote_output_heights": [
     null,
     59.5625
    ]
   },
   "source": "test_wiki_cat = \"Category:Board games introduced in 1995\"\ndef return_new_year_cats(wiki_cat):\n    year_pattern = re.compile('(19|20)\\d{2}s?')\n    check_for_year = re.search(year_pattern, wiki_cat)\n\n    curr_year = dt.datetime.now().year\n\n    new_cat_list = []\n\n    if check_for_year != None:\n        print('found', check_for_year.group(0), 'in category:', wiki_cat)        \n        found_year = check_for_year.group(0)\n\n        if 's' in found_year:\n            new_category = wiki_cat.replace(found_year, '2020s')\n            print(new_category)\n            #check category exists\n            pages_in_new_cat = len(get_wiki_wiki_pages_for_cat_members(new_category).categorymembers.keys())\n            if pages_in_new_cat > 0:\n                # add cat to existing list\n                print(pages_in_new_cat, 'exists!')\n                new_cat_list.append(new_category)\n        else:\n            for pot_year in [str(x) for x in [curr_year - i for i in range(5)]]:\n                \n                print(pot_year)\n                new_category = wiki_cat.replace(found_year, pot_year)\n                #check category exists\n                pages_in_new_cat = len(get_wiki_wiki_pages_for_cat_members(new_category).categorymembers.keys())\n                if pages_in_new_cat > 0:\n                    # add cat to existing list\n                    print(pages_in_new_cat, 'exists!')\n                    new_cat_list.append(new_category)\n                \n\n    return new_cat_list\n\nreturn_new_year_cats(test_wiki_cat)\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "found 1995 in category: Category:Board games introduced in 1995\n2022\n2021\n2020\n5 exists!\n2019\n8 exists!\n2018\n6 exists!\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 19,
     "data": {
      "text/plain": "['Category:Board games introduced in 2020',\n 'Category:Board games introduced in 2019',\n 'Category:Board games introduced in 2018']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c2c0aad1-6879-496e-bb71-e2241f487e3e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "50d4eaff",
    "execution_start": 1649992314233,
    "execution_millis": 101,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "def expand_years_in_cats_to_modern(list_wiki_cats):\n    new_year_cats_to_add = []\n    # SSLError: HTTPSConnectionPool(host='en.wikipedia.org', port=443)\n\n    for cat in list_wiki_cats:    \n        print(\"****\", cat)\n        try:\n            new_year_cats_to_add.append(return_new_year_cats(cat))\n\n        except requests.exceptions.SSLError:\n            print(\"SSLError exception caught!!!!!!!!!!!!!!!\")\n            time.sleep(5)\n            new_year_cats_to_add.append(return_new_year_cats(cat))   \n\n    return new_year_cats_to_add\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bab81a13-9a7d-4201-98e5-eaf506d70108",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6c692466",
    "execution_start": 1649992314341,
    "execution_millis": 94,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "def get_all_combined_wiki_cats(list_wiki_cats):\n    combined_wiki_cats = list_wiki_cats\n    for year_cats in expand_years_in_cats_to_modern(list_wiki_cats):\n        combined_wiki_cats = list(set(combined_wiki_cats + year_cats))\n    return combined_wiki_cats\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3c0d01a7-48b8-4f70-b0c1-29d19a6ae0c7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b757e4fa",
    "execution_start": 1649992314452,
    "execution_millis": 154,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 927
   },
   "source": "def make_cat_content_dict_from_cats(wiki_cats, wiki_term, mvp_flag, max_num_wiki_articles_per_cat = 200):\n    # given the filtered cats, try getting the summaries for all the pages mentioned into a dict, to pass to Kim\n       \n    page_cat_content_dict = dict()\n    \n    pkl_file_name = './output_step1/wiki_200_cat_content_' + wiki_term.replace(' ', '_') + '.pickle'\n\n    if mvp_flag and file_exists(pkl_file_name):\n        print('mvp! wikipedia cat content already exists.')\n        with open(pkl_file_name, 'rb') as handle:\n            page_cat_content_dict = pickle.load(handle)\n    else:\n\n        for idx, cat in enumerate(wiki_cats):\n                \n            page_content_dict = dict()\n\n            try:       \n                cat_page_member_keys = get_wiki_wiki_pages_for_cat_members(cat).categorymembers.keys()\n            except requests.exceptions.SSLError:\n                print(\"SSLError exception caught!!!!!!!!!!!!!!!\")\n                time.sleep(5)\n                cat_page_member_keys = get_wiki_wiki_pages_for_cat_members(cat).categorymembers.keys()\n\n            print(cat, idx+1, 'of', len(wiki_cats), ':', len(cat_page_member_keys))\n            remove_from_pages = ['Category:', 'List of', 'Comparison of'] + [wiki_term]\n\n            # list_of_filt_pages = [page for page in list(cat_page_member_keys)[:100] if not any(x.lower() in page.lower() for x in remove_from_pages)]\n            list_of_filt_pages = [page for page in list(cat_page_member_keys) if not any(x.lower() in page.lower() for x in remove_from_pages)][:max_num_wiki_articles_per_cat]\n\n            for filt_page in list_of_filt_pages:            \n                try:                \n                    page_content_dict[filt_page] = wikipedia.page(filt_page, auto_suggest=False).content                \n                except wikipedia.DisambiguationError:\n                    print(\"Oops! DisambiguationError, trying next result\")                \n                    continue\n            \n            page_cat_content_dict[cat] = page_content_dict\n\n        print('Dumping wikipedia cat content file')\n        with open(pkl_file_name, 'wb') as handle:\n            pickle.dump(page_cat_content_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    return page_cat_content_dict\n\n    # need to catch timeout here, for hitting API too often\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "63d5a7739ea24ba1bac72020535c458c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1649992314610,
    "execution_millis": 295888326,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "01f7352ce1474621b61b799754ee7e93",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "77f66f77",
    "execution_start": 1649992314619,
    "execution_millis": 76,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "#wiki_cats",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "faa5e9a1-4b87-4872-84ed-a4a4901eaa58",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "faef2f6",
    "execution_start": 1649992314697,
    "execution_millis": 159,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 549
   },
   "source": "def get_whitelist_dicts_by_cat(wiki_cats, wiki_term):\n    #print(wiki_cats)\n    # to get whitelist of all terms to search for in sentences from Kim deemed to be related to our category\n    white_list_dict = dict()\n    for cat in wiki_cats:\n        cat_page = get_wiki_wiki_pages_for_cat_members(cat)\n        print(cat)#, len(cat_page.categorymembers.keys()))\n        remove_from_pages = ['Category:', 'List of', 'Comparison of'] + [wiki_term]\n\n        list_of_filt_pages = [page for page in cat_page.categorymembers.keys() if not any(x.lower() in page.lower() for x in remove_from_pages)]\n\n        # get rid of everything between parens like this: 'Chimera (South Korean TV series)',\n        # https://stackoverflow.com/questions/29570771/re-sub-on-lists-python-3\n        # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n        # https://stackoverflow.com/questions/71023854/how-to-find-subcategories-and-subpages-on-wikipedia-using-pywikibot\n        \n        list_of_filt_pages_nothing_in_parens = [re.sub(r'\\([^)]*\\)', '', i) for i in list_of_filt_pages]\n\n        list_of_filt_pages_no_parens = [i.replace('(', '').replace(')', '') for i in list_of_filt_pages]\n\n        list_of_filt_pages_no_parens_strip = list(set([i.strip() for i in list_of_filt_pages_no_parens]))\n\n        white_list_dict[cat] = list_of_filt_pages_no_parens_strip\n\n    return white_list_dict\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e4eb500305a542b4ae842b07fd0f971c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3f1b10ba",
    "execution_start": 1649992314856,
    "execution_millis": 102,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 531
   },
   "source": "def filter_whitelist_dict_for_common_words(white_list_dict, wiki_term):\n    filt_white_list = dict()\n    # remove words that are too common in each category\n    # rule: appear at least 10 times, and be in greater than 20% of all entries\n\n    for k, v in white_list_dict.items(): # {category:list of titles}\n        print(len(v), k, v)\n        words = Counter()\n        for phrase in v:\n            words.update(phrase.split())\n        print(words)\n        \n        words_to_remove = []\n        for word, count in words.most_common():\n            if (count < 10):\n                break\n            if (count/len(v) > .2):\n                words_to_remove.append(word)\n\n        print(\"remove:\", words_to_remove)\n\n        p = re.compile('|'.join(map(re.escape, words_to_remove))) # escape to handle metachars\n        filt_white_list[k] = [' '.join(p.sub('', s).split()) for s in v]\n\n    return filt_white_list\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d7e6d2c2a0ec4a9b874b481b34ab6239",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4954035f",
    "execution_start": 1649992314962,
    "execution_millis": 169,
    "owner_user_id": "9187ece3-39a6-4bea-aed6-9a68f93aaf4f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "def make_white_list_cat_content_files(wiki_cats, wiki_term, mvp_flag):\n    make_cat_content_dict_from_cats(wiki_cats, wiki_term, mvp_flag)\n    \n    white_list_dict = get_whitelist_dicts_by_cat(wiki_cats, wiki_term)\n    white_list_dict\n\n    filt_white_list = filter_whitelist_dict_for_common_words(white_list_dict, wiki_term)\n\n    filt_white_list\n\n    \n\n    with open('./output_step1/white_list_200_' + wiki_term.replace(' ', '_') + '.pickle', 'wb') as handle:\n        pickle.dump(filt_white_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    print(wiki_term)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7f6a58c7074845b9b135223e84c4fc04",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5e3bced4",
    "execution_start": 1649992344805,
    "execution_millis": 100125,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 953
   },
   "source": "test_terms = ['model t', 'squid game', 'lost tv', 'apple iphone', \\\n                'obama', 'trump', 'subway tile', 'sport', 'mandalorian',\\\n                'gamestop', 'ps5', 'bitcoin', 'ketogenic diet',\\\n                'dogecoin', 'ford bronco', 'ted lasso', 'pickle ball',\\\n                'data science', 'crocs', 'terraforming mars', 'final fantasy',\\\n                'catan', 'steve jobs', 'batman', 'tesla motors', 'cronut', 'cryptocurrency',\\\n                'elon musk', 'beastie boys', 'birkin bag', 'Game Stop Short Squeeze', 'oxycontin']\n\nterm = 'tesla motors' #test_terms[21] cronut, pickleball\nmvp_flag = True\n\nnlp_cat_phrase, wiki_cats, init_wiki_cats, wiki_term = get_category_from_search_term(term)\n# # Try search for all categories that are cosine close to search category\n\nmake_white_list_cat_content_files(wiki_cats, wiki_term, mvp_flag)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "first_wiki_term: Tesla, Inc.\nnlp phrase: ['American', 'automotive', 'electric', 'vehicle', 'company']\nwiki_cats: ['Category:2003 establishments in California', 'Category:2010 initial public offerings', 'Category:American companies established in 2003', 'Category:Battery electric vehicle manufacturers', 'Category:Car brands', 'Category:Car manufacturers of the United States', 'Category:Companies based in Palo Alto, California', 'Category:Companies in the Nasdaq-100', 'Category:Companies listed on the Nasdaq', 'Category:Electric motor manufacturers', 'Category:Electric vehicle battery manufacturers', 'Category:Electric vehicle infrastructure developers', 'Category:Electric vehicle manufacturers of the United States', 'Category:Elon Musk', 'Category:Luxury motor vehicle manufacturers', 'Category:Manufacturing companies based in California', 'Category:Manufacturing companies based in the San Francisco Bay Area', 'Category:Motor vehicle manufacturers based in California', 'Category:Motor vehicle manufacturers based in Texas', 'Category:Production electric cars', 'Category:Sports car manufacturers', 'Category:Tesla, Inc.', 'Category:Vehicle manufacturing companies established in 2003']\n\nRemove wiki-cats too close to actual term(first term)\n['Tesla, Inc.', 'Category:2003 establishments in California', 'Category:2010 initial public offerings', 'Category:American companies established in 2003', 'Category:Battery electric vehicle manufacturers', 'Category:Car brands', 'Category:Car manufacturers of the United States', 'Category:Companies based in Palo Alto, California', 'Category:Companies in the Nasdaq-100', 'Category:Companies listed on the Nasdaq', 'Category:Electric motor manufacturers', 'Category:Electric vehicle battery manufacturers', 'Category:Electric vehicle infrastructure developers', 'Category:Electric vehicle manufacturers of the United States', 'Category:Elon Musk', 'Category:Luxury motor vehicle manufacturers', 'Category:Manufacturing companies based in California', 'Category:Manufacturing companies based in the San Francisco Bay Area', 'Category:Motor vehicle manufacturers based in California', 'Category:Motor vehicle manufacturers based in Texas', 'Category:Production electric cars', 'Category:Sports car manufacturers', 'Category:Tesla, Inc.', 'Category:Vehicle manufacturing companies established in 2003']\n[1.0000004  0.21034178 0.3373965  0.4715429  0.5394736  0.35621905\n 0.5021637  0.45848846 0.3637002  0.35080108 0.54590875 0.5345715\n 0.45285487 0.5635325  0.37240148 0.45028663 0.45163202 0.42556953\n 0.4745108  0.5072607  0.44965756 0.47200045 0.8289722  0.47757053]\n[21]\nafter rem: ['Category:2003 establishments in California', 'Category:2010 initial public offerings', 'Category:American companies established in 2003', 'Category:Battery electric vehicle manufacturers', 'Category:Car brands', 'Category:Car manufacturers of the United States', 'Category:Companies based in Palo Alto, California', 'Category:Companies in the Nasdaq-100', 'Category:Companies listed on the Nasdaq', 'Category:Electric motor manufacturers', 'Category:Electric vehicle battery manufacturers', 'Category:Electric vehicle infrastructure developers', 'Category:Electric vehicle manufacturers of the United States', 'Category:Elon Musk', 'Category:Luxury motor vehicle manufacturers', 'Category:Manufacturing companies based in California', 'Category:Manufacturing companies based in the San Francisco Bay Area', 'Category:Motor vehicle manufacturers based in California', 'Category:Motor vehicle manufacturers based in Texas', 'Category:Production electric cars', 'Category:Sports car manufacturers', 'Category:Vehicle manufacturing companies established in 2003']\nKeep wiki-cats not too far to found category(first term)\n['American automotive electric vehicle company', 'Category:2003 establishments in California', 'Category:2010 initial public offerings', 'Category:American companies established in 2003', 'Category:Battery electric vehicle manufacturers', 'Category:Car brands', 'Category:Car manufacturers of the United States', 'Category:Companies based in Palo Alto, California', 'Category:Companies in the Nasdaq-100', 'Category:Companies listed on the Nasdaq', 'Category:Electric motor manufacturers', 'Category:Electric vehicle battery manufacturers', 'Category:Electric vehicle infrastructure developers', 'Category:Electric vehicle manufacturers of the United States', 'Category:Elon Musk', 'Category:Luxury motor vehicle manufacturers', 'Category:Manufacturing companies based in California', 'Category:Manufacturing companies based in the San Francisco Bay Area', 'Category:Motor vehicle manufacturers based in California', 'Category:Motor vehicle manufacturers based in Texas', 'Category:Production electric cars', 'Category:Sports car manufacturers', 'Category:Vehicle manufacturing companies established in 2003']\n[0.9999998  0.17170826 0.22931737 0.51577294 0.7203543  0.43290424\n 0.59277695 0.3605907  0.33250192 0.30795953 0.6455082  0.686897\n 0.5983746  0.7448915  0.13977644 0.5578878  0.44056973 0.37750804\n 0.5966015  0.60579497 0.6166378  0.526788   0.58622825]\nkeep idx: [ 3 12]\npre-last-filt: ['Category:2003 establishments in California', 'Category:2010 initial public offerings', 'Category:American companies established in 2003', 'Category:Battery electric vehicle manufacturers', 'Category:Car brands', 'Category:Car manufacturers of the United States', 'Category:Companies based in Palo Alto, California', 'Category:Companies in the Nasdaq-100', 'Category:Companies listed on the Nasdaq', 'Category:Electric motor manufacturers', 'Category:Electric vehicle battery manufacturers', 'Category:Electric vehicle infrastructure developers', 'Category:Electric vehicle manufacturers of the United States', 'Category:Elon Musk', 'Category:Luxury motor vehicle manufacturers', 'Category:Manufacturing companies based in California', 'Category:Manufacturing companies based in the San Francisco Bay Area', 'Category:Motor vehicle manufacturers based in California', 'Category:Motor vehicle manufacturers based in Texas', 'Category:Production electric cars', 'Category:Sports car manufacturers', 'Category:Vehicle manufacturing companies established in 2003']\npost-last-filt: ['Category:Battery electric vehicle manufacturers', 'Category:Electric vehicle manufacturers of the United States']\n**** Category:Battery electric vehicle manufacturers\n**** Category:Electric vehicle manufacturers of the United States\nCategory:Battery electric vehicle manufacturers 1 of 2 : 101\nCategory:Electric vehicle manufacturers of the United States 2 of 2 : 96\nDumping wikipedia cat content file\nCategory:Battery electric vehicle manufacturers\nCategory:Electric vehicle manufacturers of the United States\n93 Category:Battery electric vehicle manufacturers ['Workhorse Group', 'Wildfire motor company', 'Volkswagen Group', 'Riker Electric Vehicle Company', 'Coda Automotive', 'Metrovick electric vehicles', 'Advanced Battery Technologies', 'Mullen Technologies', 'Bright Automotive', 'EdisonFuture', 'BrightDrop', 'Wales & Edwards', 'Apex Motors', 'Lucid Motors', 'Wuzhoulong', 'Segway Inc.', 'Helecs Vehicles', 'Hurtan', 'Lewis Electruk', 'Boulder Electric Vehicle', 'Heibao Auto', 'Aptera Motors', 'Loremo', 'Rivian', 'KleenSpeed Technologies', 'Zagato Zele', 'Volta Trucks', 'Canoo', 'Morrison-Electricar', 'National Motor Vehicle Company', 'Graiseley Electric Vehicles', 'Pininfarina', 'Ioniq', 'Mahindra Electric', 'Ford Motor Company', 'Smith Electric Vehicles', 'General Motors', 'Modec', 'Lordstown Motors', 'ZAP motor company', 'Tara International', 'Ather Energy', 'Manulectric', 'Tacita motorcycles', 'Miles Electric Vehicles', 'Polestar', 'Stevens Vehicles', 'Sunbeam Commercial Vehicles', 'RAESR', 'Rimac Automobili', 'Ross Auto Engineering', 'Nikola Corporation', 'Nissan', 'Renault', 'BYD Auto', 'Harbilt Electric Trucks', 'Vmoto', 'Brush Traction', 'Apollo Energy Systems', 'Byton company', 'Tomlinson Electric Vehicles', 'Nissan electric vehicles', 'Jet Industries', 'CT&T United', 'Renault Samsung Motors', 'DOK-ING', 'AC Propulsion', 'Arrival company', 'PiÃ«ch Automotive', 'Omega Seiki Mobility', 'Scottish Aviation', 'Lightning Car Company', 'Think Global', 'Uniti car', 'Alta Motors', 'AVL engineering company', 'Ola Electric', 'Battery Manufacturing Association', 'Li Auto', 'Automobili Pininfarina', 'Midland Electric Vehicles', 'Green Vehicles', 'Electrorides', 'Victor Electrics', 'Partridge Wilson Engineering', 'Global Electric Motorcars', 'Einride', 'Ruf Automobile', 'Myers EV', 'Aurica Motors', 'Fisker Inc.', 'Stuart automobile', 'Faraday Future']\nCounter({'Electric': 11, 'Vehicles': 9, 'Motors': 8, 'company': 5, 'Company': 4, 'Auto': 4, 'Vehicle': 3, 'Automotive': 3, 'Technologies': 3, 'Group': 2, 'motor': 2, 'electric': 2, 'vehicles': 2, 'Battery': 2, 'Inc.': 2, 'Trucks': 2, 'Motor': 2, 'Pininfarina': 2, 'Energy': 2, 'Automobili': 2, 'Engineering': 2, 'Nissan': 2, 'Renault': 2, 'Global': 2, 'Workhorse': 1, 'Wildfire': 1, 'Volkswagen': 1, 'Riker': 1, 'Coda': 1, 'Metrovick': 1, 'Advanced': 1, 'Mullen': 1, 'Bright': 1, 'EdisonFuture': 1, 'BrightDrop': 1, 'Wales': 1, '&': 1, 'Edwards': 1, 'Apex': 1, 'Lucid': 1, 'Wuzhoulong': 1, 'Segway': 1, 'Helecs': 1, 'Hurtan': 1, 'Lewis': 1, 'Electruk': 1, 'Boulder': 1, 'Heibao': 1, 'Aptera': 1, 'Loremo': 1, 'Rivian': 1, 'KleenSpeed': 1, 'Zagato': 1, 'Zele': 1, 'Volta': 1, 'Canoo': 1, 'Morrison-Electricar': 1, 'National': 1, 'Graiseley': 1, 'Ioniq': 1, 'Mahindra': 1, 'Ford': 1, 'Smith': 1, 'General': 1, 'Modec': 1, 'Lordstown': 1, 'ZAP': 1, 'Tara': 1, 'International': 1, 'Ather': 1, 'Manulectric': 1, 'Tacita': 1, 'motorcycles': 1, 'Miles': 1, 'Polestar': 1, 'Stevens': 1, 'Sunbeam': 1, 'Commercial': 1, 'RAESR': 1, 'Rimac': 1, 'Ross': 1, 'Nikola': 1, 'Corporation': 1, 'BYD': 1, 'Harbilt': 1, 'Vmoto': 1, 'Brush': 1, 'Traction': 1, 'Apollo': 1, 'Systems': 1, 'Byton': 1, 'Tomlinson': 1, 'Jet': 1, 'Industries': 1, 'CT&T': 1, 'United': 1, 'Samsung': 1, 'DOK-ING': 1, 'AC': 1, 'Propulsion': 1, 'Arrival': 1, 'PiÃ«ch': 1, 'Omega': 1, 'Seiki': 1, 'Mobility': 1, 'Scottish': 1, 'Aviation': 1, 'Lightning': 1, 'Car': 1, 'Think': 1, 'Uniti': 1, 'car': 1, 'Alta': 1, 'AVL': 1, 'engineering': 1, 'Ola': 1, 'Manufacturing': 1, 'Association': 1, 'Li': 1, 'Midland': 1, 'Green': 1, 'Electrorides': 1, 'Victor': 1, 'Electrics': 1, 'Partridge': 1, 'Wilson': 1, 'Motorcars': 1, 'Einride': 1, 'Ruf': 1, 'Automobile': 1, 'Myers': 1, 'EV': 1, 'Aurica': 1, 'Fisker': 1, 'Stuart': 1, 'automobile': 1, 'Faraday': 1, 'Future': 1})\nremove: []\n83 Category:Electric vehicle manufacturers of the United States ['Workhorse Group', 'Wildfire motor company', 'Proterra bus manufacturer', 'Riker Electric Vehicle Company', 'Coda Automotive', 'Current Motor Company', 'Mullen Technologies', 'Bright Automotive', 'EdisonFuture', 'BrightDrop', 'St. Louis Car Company', 'AeroVironment', 'Lucid Motors', 'Electric Transit, Inc.', 'Segway Inc.', 'Boulder Electric Vehicle', 'Aptera Motors', 'Gomaco Trolley Company', 'G. C. Kuhlman Car Company', 'Rivian', 'Stallion Bus and Transit Corp.', 'Karma Automotive', 'VIA Motors', 'ENC company', 'KleenSpeed Technologies', 'J. G. Brill Company', 'Mack Trucks', 'Canoo', 'National Motor Vehicle Company', 'Arcimoto', 'Ford Motor Company', 'General Motors', 'Lordstown Motors', 'ZAP motor company', 'Evolve Motorcycles', 'American Car Company', 'Thomas Built Buses', 'Bollinger Motors', 'Miles Electric Vehicles', 'Environmental Performance Vehicles', 'Wikispeed', 'McGuire-Cummings Manufacturing Company', 'United Streetcar', 'RAESR', 'Nikola Corporation', 'Bachelle Electric', 'Twin Coach', 'W. L. Holman Car Company', 'Motiv Power Systems', 'Apollo Energy Systems', 'Jet Industries', 'Allison Transmission', 'Jewett Car Company', 'AM General', 'Pressed Steel Car Company', 'Wheego Technologies', 'Rad Power Bikes', 'AC Propulsion', 'Lit Motors', 'Brownell Car Company', 'John Stephenson Company', 'IC Bus', 'Niles Car and Manufacturing Company', 'Local Motors', 'Fisker Automotive', 'Perley A. Thomas Car Works', 'Seres automobiles', 'SSC North America', 'Laclede Car Company', 'ElDorado bus manufacturer', 'North American Bus Industries', 'Green Vehicles', 'Electrorides', 'Global Electric Motorcars', 'Ideanomics', 'Phoenix Motorcars', 'Neoplan USA', 'Myers EV', 'Aurica Motors', 'Optima Bus Corporation', 'Fisker Inc.', 'Stuart automobile', 'Faraday Future']\nCounter({'Company': 17, 'Car': 10, 'Motors': 9, 'Electric': 6, 'Automotive': 4, 'Bus': 4, 'company': 3, 'Vehicle': 3, 'Motor': 3, 'Technologies': 3, 'Inc.': 3, 'Vehicles': 3, 'motor': 2, 'bus': 2, 'manufacturer': 2, 'G.': 2, 'and': 2, 'General': 2, 'American': 2, 'Thomas': 2, 'Manufacturing': 2, 'Corporation': 2, 'Power': 2, 'Systems': 2, 'Industries': 2, 'Fisker': 2, 'North': 2, 'Motorcars': 2, 'Workhorse': 1, 'Group': 1, 'Wildfire': 1, 'Proterra': 1, 'Riker': 1, 'Coda': 1, 'Current': 1, 'Mullen': 1, 'Bright': 1, 'EdisonFuture': 1, 'BrightDrop': 1, 'St.': 1, 'Louis': 1, 'AeroVironment': 1, 'Lucid': 1, 'Transit,': 1, 'Segway': 1, 'Boulder': 1, 'Aptera': 1, 'Gomaco': 1, 'Trolley': 1, 'C.': 1, 'Kuhlman': 1, 'Rivian': 1, 'Stallion': 1, 'Transit': 1, 'Corp.': 1, 'Karma': 1, 'VIA': 1, 'ENC': 1, 'KleenSpeed': 1, 'J.': 1, 'Brill': 1, 'Mack': 1, 'Trucks': 1, 'Canoo': 1, 'National': 1, 'Arcimoto': 1, 'Ford': 1, 'Lordstown': 1, 'ZAP': 1, 'Evolve': 1, 'Motorcycles': 1, 'Built': 1, 'Buses': 1, 'Bollinger': 1, 'Miles': 1, 'Environmental': 1, 'Performance': 1, 'Wikispeed': 1, 'McGuire-Cummings': 1, 'United': 1, 'Streetcar': 1, 'RAESR': 1, 'Nikola': 1, 'Bachelle': 1, 'Twin': 1, 'Coach': 1, 'W.': 1, 'L.': 1, 'Holman': 1, 'Motiv': 1, 'Apollo': 1, 'Energy': 1, 'Jet': 1, 'Allison': 1, 'Transmission': 1, 'Jewett': 1, 'AM': 1, 'Pressed': 1, 'Steel': 1, 'Wheego': 1, 'Rad': 1, 'Bikes': 1, 'AC': 1, 'Propulsion': 1, 'Lit': 1, 'Brownell': 1, 'John': 1, 'Stephenson': 1, 'IC': 1, 'Niles': 1, 'Local': 1, 'Perley': 1, 'A.': 1, 'Works': 1, 'Seres': 1, 'automobiles': 1, 'SSC': 1, 'America': 1, 'Laclede': 1, 'ElDorado': 1, 'Green': 1, 'Electrorides': 1, 'Global': 1, 'Ideanomics': 1, 'Phoenix': 1, 'Neoplan': 1, 'USA': 1, 'Myers': 1, 'EV': 1, 'Aurica': 1, 'Optima': 1, 'Stuart': 1, 'automobile': 1, 'Faraday': 1, 'Future': 1})\nremove: ['Company']\nTesla, Inc.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "686bea5b231640a9bad70dd351059bd4",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "9294afce",
    "execution_start": 1649703560492,
    "execution_millis": 102,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 117
   },
   "source": "# for term in test_terms:\n#     first_wiki_term, wiki_page = get_first_unambiguous_wiki_term_and_page(term)\n#     print(term, ':', first_wiki_term, ':', get_nlp_category_phrase(wiki_page))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e8dc11e71c34452fb9367d4499281662",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "8c12abcd",
    "execution_start": 1649703560600,
    "execution_millis": 107,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "# expanded_wiki_cats = \n# print(wiki_cats)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "01951f9cdd56477abe7ef2de1f899326",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "356eaf3f",
    "execution_start": 1649703560716,
    "execution_millis": 138,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "##expand_years_in_cats_to_modern(wiki_cats)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "48311d4657b641b28a00b71e6cd089c2",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b5aa4f56",
    "execution_start": 1649703560871,
    "execution_millis": 83330,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 262.75
   },
   "source": "%%time\n\n\n\n\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Category:Electric vehicle manufacturers of the United States 1 of 2 : 96\nCategory:Battery electric vehicle manufacturers 2 of 2 : 101\nCPU times: user 11.1 s, sys: 466 ms, total: 11.5 s\nWall time: 1min 23s\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "6094baef766a487b9262b8e4f7792821",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cb4ea6e1",
    "execution_start": 1649703644211,
    "execution_millis": 1796,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "# for k,v in page_cat_content_dict.items():\n#     print(k, len(v))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a866d8ab593844b68118e482eb604d6a",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "77f66f77",
    "execution_start": 1649703646017,
    "execution_millis": 156,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "#wiki_cats",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "48e9de0c51214766acb9dd0d01b96295",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b31fd813",
    "execution_start": 1649986393236,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "790cf476a4c94d7d908965f86167d627",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "681f4679",
    "execution_start": 1649703646526,
    "execution_millis": 103,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "#white_list_dict.keys()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a20242ab9c734fd78c97cc1f9b330180",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1649703646641,
    "execution_millis": 118,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "ae299f11-76fe-443e-94af-94fedcbe782e",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "9c1555b4",
    "execution_start": 1649703646775,
    "execution_millis": 105,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "# with open('./output_step1/wiki_100summaries_' + wiki_term.replace(' ', '') + '.pickle', 'wb') as handle:\n#     pickle.dump(page_summary_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1370b674-a678-455f-9a73-805949b4cd88",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1649703646886,
    "execution_millis": 155,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 112.1875
   },
   "source": "",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Tesla, Inc.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8eda2ea9-9ace-4be2-8098-a66d83257e8e",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "9b9dbcce",
    "execution_start": 1649703647049,
    "execution_millis": 105,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "# test_model = model.encode(['catan', 'wingspan', 'Bananagrams', 'missle'])\n\n# cos_test = util.pytorch_cos_sim(test_model, test_model)[0].numpy()\n# print(cos_test)\n# #rem_idx = np.where(cos_remove > .7)[0]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "fb254207-ec77-41f1-9e37-65616c87bd3e",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "eea86363",
    "execution_start": 1649703647164,
    "execution_millis": 117,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 117
   },
   "source": "# # attempt at searching for more categories, if what we found above isn't enough\n# search_results = wikipedia.search('Category:dietary therapy', results=100, suggestion=False)\n# print(search_results)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8defb22e-7e7f-49dd-9cc3-3c6d9bd59280",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "36b441b2",
    "execution_start": 1649703647374,
    "execution_millis": 86,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "# wikipedia.page('List of board games', auto_suggest=False).summary",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "6de77bd0-d457-44fe-a236-93a471448d74",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "bbc4525",
    "execution_start": 1649703647460,
    "execution_millis": 192,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "\n\n# site = pw.Site(\"en\", \"wikipedia\")\n# print([\n#     cat.title()\n#     for cat in pw.Page(site, 'support-vector machine').categories()\n#     if 'hidden' not in cat.categoryinfo\n# ])\n\n# p = pw.Page(site, 'support-vector machine')\n# list(p.categories())\n\n# for cat in p.categories():\n#     print(cat)\n#     print(cat.categoryinfo)\n#     print()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7c8c1d84-5076-400b-a753-408e8bacf748",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1649703647652,
    "execution_millis": 36,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=90b052a7-f47d-474e-888f-9345355cfd9a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "66542857-f646-490d-b341-dadf1760bc19",
  "deepnote_execution_queue": []
 }
}